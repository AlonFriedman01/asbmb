---
output:
  word_document: default
  html_document: default
  pdf_document: default
---
```{css, echo = FALSE}
.remark-slide-content {
  font-size: 28px;
  padding: 20px 80px 20px 80px;
}
.remark-code, .remark-inline-code {
  background: #f0f0f0;
}
.remark-code {
  font-size: 24px;
}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
```
Summer 2021
========================================================
author: Alon Friedman
date: June 2021
autosize: true
![USF logo](images/USF_logo.png){width=30%}
```{r}

```

================================================
<style>
.reveal .slides section .slideContent{
    font-size: 20pt;
}
</style>  
Data science professionals often used two distinct programming languages that help to analyze big data. The two programming languages are _Python_ and _R_ to visualize their study result.

In this presentation, I will focus on _R_ and visualization. 


>>>[Download RStudio](https://www.rstudio.com/products/rstudio/download/) 


As a platform, _R_ is allocated towards statistical analysis and data visualization, but this core development consists of the extensible through packages—many of them are specialized—that are created and maintained by a developer community. 

_R_ allows us to generate visualization to extend data analysis.      

Later in my presentation, I will discuss the *Three common strategies* for working with Big Data in _R_:  
1. Sample  
2. Chunk and Pull  
3. Push Compute to Data  

\newpage

**Python** vs. **R** 
========================================================
The basis of much of data science is based on statistics, data mining, and visualization. Many of the standard statistical techniques are adequately covered by Python but if you try unconventional techniques and methodologies, you will get lost. _R_ is designated as a “language and environment for statistical computing and graphics” (What is R?, n.d.). 
There are now more than 35,000 R packages on the official repository CRAN alone! I will demonstrate how you can use GitHub to pull R packages and code to help us analyze JSONL files using the knowledge already created in _R_. 

\newpage

Why visualization and Big Data/Data science? 
========================================================
* We as humans react to visual data 60,000 times faster than text. (Mani, M., & Fei, S. 2017).   
* The first benefit of visualization with Big Data/Data science is easier to understand the data.    
* Visualization lets us distinguish the data spread over time. 
* Visualization helps us recognize similarities and random connections. 
* Playfair (1821) is widely considered the father of statistical graphics, including the most popular graphs we use today (line, bar, circle, and pie charts). 
\newpage
![1824 Playfair line graph, illustrating of how bread and stock prices are affected by war](images/Playfair2.png)


\newpage

Basic Visualization in _R_
========================================================
_R_ provides us basic visualization functions without any additional packages:
* plot: generic x-y plotting 
* barplot:  bar plots.
* hist: histograms.    	
* pie: pie charts. 
\newpage
R code for plot
========================================================

``` {r}
t=0:10
z= exp(-t/2)
plot(t,z)
```
\newpage

R code for Histogram 
========================================================
```{r}
values <- c(0.4, 0.75, 0.2, 0.6, 0.5)
hist(values)
```
\newpage
R code for pie
========================================================
```{r}
values <- c(0.4, 0.75, 0.2, 0.6, 0.5)
pie(values)
```

\newpage
**ggplot2** breaks away from traditional data imaging techniques. 
========================================================
ggplot2 ggplot2 is an R package for creating graphics, based on The Grammar of Graphics. 
One of the things it allows us to have a Canvas background. 
```{r}
options(scipen=999)  # turn off scientific notation like 1e+06
library(ggplot2)
data("midwest", package = "ggplot2")  # load the data
# midwest <- read.csv("http://goo.gl/G1K41K") # alt source 

# Init Ggplot
ggplot(midwest, aes(x=area, y=poptotal))  # area and poptotal are columns in 'midwest'
```
\newpage

**ggplot2 and Visual Grammar**
========================================================
Core components of the layered grammar of graphics using ggplot2.

* Data.
* Mapping.
* Statistical transformation (stat).
* Geometric object (geom).
* Position adjustment (position). 
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = class)) +
  geom_point() +
  ggtitle("A point geom with position and color aesthetics")
```

\newpage

**3D scatter plot**
========================================================
In order to build 3D plot, you need to have **3 numeric variables**, each being used on an axis. 
In this an example, i employed *iris* dataset. Plus I used *rgl* packages that comes with the function called *plot3d()*
```{r}
library(rgl)

# This is to output a rgl plot in a rmarkdown document. Note that you must add webgl=TRUE, results='hide' in the chuck header
#library(knitr)
#knit_hooks$set(webgl = hook_webgl)

# Data: the iris data is provided by R
data <- iris

# Add a new column with color
mycolors <- c('royalblue1', 'darkcyan', 'oldlace')
data$color <- mycolors[ as.numeric(data$Species) ]

# Plot
par(mar=c(0,0,0,0))
plot3d( 
  x=data$`Sepal.Length`, y=data$`Sepal.Width`, z=data$`Petal.Length`, 
  col = data$color, 
  type = 's', 
  radius = .1,
  xlab="Sepal Length", ylab="Sepal Width", zlab="Petal Length")

``` 
![3D](images/One.png)
\newpage

# Next  

- Using R packages
- Importing data
- Extracting data
- Working with GitHub
- Large data files in R
- Using Visualization in this work

\newpage

**Using R package**
========================================================
R is designated as a “language and environment for statistical computing and graphics” (What is R?, n.d.). This multilayered software core development consists of the extensible through packages—many of them are specialized—that are created and maintained by a developer community. 

A package is a way to organize your work in R and help share it with others. 

Each of the R packages contains sets of code (called _functions_) that accomplish specific tasks. In addition, every package also includes documentation, the data score and some tests to check everything works as it should, and data sets.
\newpage

Here are some of the most popular R packages 

-**Tidyverse**- provides a set of functions that help you get to tidy data. For more details on dplyr <https://www.tidyverse.org>

-**dplyr**-  is primarily a set of functions designed to enable dataframe manipulation of the data. 
For more details on dplyr <https://github.com/tidyverse/dplyr>

-**ggplot2**- is a package that helps to enhance the data visualization from your work in R.
For more details on ggplot2 <https://ggplot2.tidyverse.org>.

\newpage

**R packages repositories**


-*CRAN* - The Comprehensive R Archive Network

-*BioConductor*- is a set of repositories containing R packages used in the analysis of scientific data. 

-*GitHub* - is the largest code repositories that offers version control using Git. It offers the distributed version control and source code. 
\newpage

**GitHub**
========================================================
GitHub is the most popular version control system for developers of R packages. 

Using _devtools_ package, allow us to install the package directly from GitHub.

1. install.packages("devtools")

2. library("devtools")

3. install_github("name of the creator of the repository/name of the package")

\newpage

**Importing data**
========================================================

The new Rstudio interface provides easy features to import data from _csv_, _xls_, _xlsx_, _sav_, _dta_, _por_, _sas_ and _stata_ files. 
For full step by step, Rstudio provides For more details on importing data see <https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio>.

**JSON** and R. 

_JSON_ stands for JavaScript Object Notation. These files contain the data in human-readable format, i.e. as text. Like any other file format(s), one can read as well as write into the JSON files. In order to work with JSON files in R, one needs to install the *“rjson”*  package. 

_install.packages("rjson")_
_library("rjson")_

\newpage

**Extracting Data**
========================================================
There are many techniques for extracting data in R. 

Here are the most common practices:

-**Data.frame** is a list of variables of the same number of rows with unique row names, given class "data.frame" 

-The most general way to subset a data frame by rows and/or columns is the base R **Extract function ** d[rows, columns] here *d* is the data frame. 

For example:

```{r}
data <- data.frame(x1 = 1:10,
                   x2 = letters[1:10],
                   x3 = "x")
data
head(data)
```
-Extract or Replace Parts of a Data Frame.
x[i, j, drop = ]
x[i, j] <- value
x[[..., exact = TRUE]]
x[[i, j]] <- value
x$name <- value

\newpage
*Cleaning Data*

What exactly is clean data? Clean data is accurate, complete, and in a format that is ready to analyze. 

Characteristics of clean data include data that are:

-Free of duplicate rows/values
-Error-free (e.g. free of misspellings)
-Relevant (e.g. free of special characters)
-The appropriate data type for analysis
-Free of outliers  
-and using “tidy data” structure

For more information about how to clean data, I highly recommend you to visit _Brief Introduction to the 12 Steps of Data Cleaning_ [Morrow, 2013] (https://www.slideshare.net/jamorrow/brief-introduction-to-the-12-steps-of-evaluagio)

\newpage



**Large data files in R**
========================================================
R is known to have difficulties handling large data files. 

-In this presentation, we will work with the entire file in the computer memory. 

Some common recommendations for a faster process: 

-Use *data.frame* 
-Use *data.table*'s package.
-Use *sqldf* function for _csv_ files.
-Use a _SQLite database_ and employ *dplyr*'s package.
-Convert your *csv* file to a *sqlite* database in order to query. 
- Limit the number of lines you read using *fred* function under.

For example

_size_t fread(void * buffer, size_t size, size_t count, FILE * stream)_

*In this code*
**buffer**: it specifies the pointer to the block of memory with a size of at least (size*count) bytes to store the objects.

**size**: it specifies the size of each object in bytes. size_t is an unsigned integral type.

**count**: it specifies the number of elements, each one with a size of size bytes.

**stream**: it specifies the file stream to read the data from.

\newpage

**Using Visualization to help to read large data file**
========================================================
We will show how to create visualization from three different datasets and different R packages.  

The first example is using **esquisse** package. The purpose of this add-in package is to let you explore your data quickly to extract the information they hold. 

The second example is with a small dataset without the add. The third and last example is with a larger data set that holds 31 megabits and 23 columns. Both data sets were taken from the *National Oceanic and Atmospheric'* database on subject of _protein_. 

We will use four R packages:

-ggplot2- we discussed before

-igraph - Visualization Network analysis package. 
-ggalluvial-  is a ggplot2 extension for producing alluvial plots

-viridis - provides the base functions for generating the color maps in base R. 
-esquisse - is add-in is to let you explore your data quickly.

Live Demonstration [Live Demonstration](https://github.com/AlonFriedman01/asbmb/blob/main/protein8kExamples.R) 

\newpage
**You work**
========================================================
1. Log on to National Centers for Environmental Information <https://www.ncdc.noaa.gov> and search your own database. 
2. Convert the data you selected and insert to R. 
3. Then, try to select 7 common charts including: 
1. Scatter Plot
2. Historgram
3. Bar & Strack Bar Chart
4. Box Plot
5. Area Chart
6. Heat Map 
and 7. Correlogram 

1. Scatter plot - here is example code
```{r}
library(ggplot2)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + 
    geom_point()
```

2. Histogram is often used for continuous variables. It captures the data into bins and frequency.

```{r}
library(ggplot2)

# Create data
data <- data.frame(
  name=c("A","B","C","D","E") ,  
  value=c(3,12,5,18,45)
  )

# Barplot
ggplot(data, aes(x=name, y=value)) + 
  geom_bar(stat = "identity", width=0.2) 
```

Box Plot is also well recognize visual format. It allows us to combination  categorical and continuous variables. R allows us to points the outliers in the data.
```{r}
library(tidyverse)
msleep %>% glimpse()
ggplot(data = msleep, aes(x = sleep_total)) +
  geom_boxplot()
```
Heat Map uses intensity (density) of colors to display relationship between two or three or many variables in a two dimensional image.
```{r}

```
Last one, Correlgram
In this example, the darker the color, higher the co-relation between variables. 
I am using a new R package called _Corrgram_. It allows us to build this type of visualization.

```{r}
library(corrplot)
head(mtcars)
#correlation matrix
M<-cor(mtcars)
head(round(M,2))
#visualizing correlogram
#as circle
corrplot(M, method="circle")
# as pie
corrplot(M, method="pie")
# as colour
corrplot(M, method="color")
# as number
corrplot(M, method="number")

```

Enjoy 
